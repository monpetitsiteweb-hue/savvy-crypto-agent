import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    );

    const { action, symbols, startDate, endDate, userId, sourceId } = await req.json();
    console.log(`üè¶ BigQuery Collector received:`, { action, symbols, startDate, endDate, userId });

    switch (action) {
      case 'fetch_historical_data':
        return await fetchHistoricalData(supabaseClient, { symbols, startDate, endDate, userId, sourceId });
      
      case 'sync_daily_data':
        return await syncDailyData(supabaseClient, { symbols, userId, sourceId });
      
      default:
        return new Response(JSON.stringify({ error: 'Invalid action' }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
    }
  } catch (error) {
    console.error('‚ùå BigQuery Collector error:', error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});

async function fetchHistoricalData(supabaseClient: any, params: any) {
  const { symbols, startDate, endDate, userId, sourceId } = params;
  
  console.log(`üìà Fetching BigQuery historical data for symbols: ${symbols?.join(', ')}`);
  
  // TODO: Implement actual BigQuery integration
  // For now, simulate historical data
  const mockHistoricalData = symbols.map((symbol: string) => {
    const basePrice = Math.random() * 50000 + 10000;
    const daysInRange = Math.floor((new Date(endDate).getTime() - new Date(startDate).getTime()) / (1000 * 60 * 60 * 24));
    
    return Array.from({ length: Math.min(daysInRange, 100) }, (_, i) => {
      const date = new Date(startDate);
      date.setDate(date.getDate() + i);
      
      return {
        source_id: sourceId,
        user_id: userId,
        timestamp: date.toISOString(),
        symbol: symbol,
        price: basePrice * (1 + (Math.random() - 0.5) * 0.1),
        volume: Math.floor(Math.random() * 1000000),
        exchange: 'MOCK_EXCHANGE',
        market_cap: basePrice * 21000000, // Mock market cap
        source: 'bigquery',
        metadata: {
          data_quality: 'high',
          backfilled: true,
          collection_date: new Date().toISOString()
        }
      };
    });
  }).flat();

  // Insert historical data
  const { data, error } = await supabaseClient
    .from('historical_market_data')
    .upsert(mockHistoricalData, { 
      onConflict: 'symbol,timestamp', 
      ignoreDuplicates: true 
    });

  if (error) {
    console.error('‚ùå Error inserting historical data:', error);
    throw error;
  }

  console.log(`‚úÖ Successfully inserted ${mockHistoricalData.length} historical records`);
  
  return new Response(JSON.stringify({ 
    success: true, 
    recordsInserted: mockHistoricalData.length,
    message: 'Historical data synced successfully'
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}

async function syncDailyData(supabaseClient: any, params: any) {
  const { symbols, userId, sourceId } = params;
  
  console.log(`üìÖ Syncing daily BigQuery data for symbols: ${symbols?.join(', ')}`);
  
  // TODO: Implement actual BigQuery daily sync
  // For now, simulate daily data for today
  const today = new Date().toISOString().split('T')[0];
  
  const dailyData = symbols.map((symbol: string) => ({
    source_id: sourceId,
    user_id: userId,
    timestamp: new Date().toISOString(),
    symbol: symbol,
    price: Math.random() * 50000 + 10000,
    volume: Math.floor(Math.random() * 1000000),
    exchange: 'AGGREGATED',
    market_cap: (Math.random() * 50000 + 10000) * 21000000,
    source: 'bigquery',
    metadata: {
      data_quality: 'high',
      real_time: false,
      sync_date: new Date().toISOString()
    }
  }));

  const { data, error } = await supabaseClient
    .from('historical_market_data')
    .upsert(dailyData, { 
      onConflict: 'symbol,timestamp', 
      ignoreDuplicates: true 
    });

  if (error) {
    console.error('‚ùå Error syncing daily data:', error);
    throw error;
  }

  console.log(`‚úÖ Successfully synced ${dailyData.length} daily records`);
  
  return new Response(JSON.stringify({ 
    success: true, 
    recordsInserted: dailyData.length,
    message: 'Daily data synced successfully'
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}